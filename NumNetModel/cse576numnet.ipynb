{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sbisoyi\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cse576.ipynb  numnet_plus  ondemand  perl5\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/llamazing/numnet_plus.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sbisoyi/numnet_plus\n"
     ]
    }
   ],
   "source": [
    "%cd numnet_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install word2number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O drop_dataset.zip https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip drop_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sbisoyi/numnet_plus/drop_dataset\n"
     ]
    }
   ],
   "source": [
    "%cd drop_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir roberta.large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sbisoyi/numnet_plus/drop_dataset/roberta.large\n"
     ]
    }
   ],
   "source": [
    "%cd roberta.large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O pytorch_model.bin https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O config.json https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O vocab.json https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O merges.txt https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sbisoyi/numnet_plus\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ SEED=345\n",
      "+ LR=5e-4\n",
      "+ BLR=1.5e-5\n",
      "+ WD=5e-5\n",
      "+ BWD=0.01\n",
      "+ TMSPAN=\n",
      "+ BASE_DIR=.\n",
      "+ DATA_DIR=./drop_dataset\n",
      "+ CODE_DIR=.\n",
      "+ '[' == tag_mspan ']'\n",
      "train.sh: line 17: [: ==: unary operator expected\n",
      "+ echo 'Use mspan model...'\n",
      "Use mspan model...\n",
      "+ CACHED_TRAIN=./drop_dataset/cached_roberta_train.pkl\n",
      "+ CACHED_DEV=./drop_dataset/cached_roberta_dev.pkl\n",
      "+ MODEL_CONFIG='--gcn_steps 3 --use_gcn'\n",
      "+ '[' '(' '!' -e ./drop_dataset/cached_roberta_train.pkl ')' -o '(' '!' -e ./drop_dataset/cached_roberta_dev.pkl ')' ']'\n",
      "+ SAVE_DIR=./numnet_plus_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01\n",
      "+ DATA_CONFIG='--data_dir ./drop_dataset --save_dir ./numnet_plus_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01'\n",
      "+ TRAIN_CONFIG='--batch_size 12 --eval_batch_size 5 --max_epoch 3 --warmup 0.06 --optimizer adam               --learning_rate 5e-4 --weight_decay 5e-5 --seed 345 --gradient_accumulation_steps 4               --bert_learning_rate 1.5e-5 --bert_weight_decay 0.01 --log_per_updates 100 --eps 1e-6'\n",
      "+ BERT_CONFIG='--roberta_model ./drop_dataset/roberta.large'\n",
      "+ echo 'Start training...'\n",
      "Start training...\n",
      "+ python ./roberta_gcn_cli.py --data_dir ./drop_dataset --save_dir ./numnet_plus_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01 --batch_size 12 --eval_batch_size 5 --max_epoch 3 --warmup 0.06 --optimizer adam --learning_rate 5e-4 --weight_decay 5e-5 --seed 345 --gradient_accumulation_steps 4 --bert_learning_rate 1.5e-5 --bert_weight_decay 0.01 --log_per_updates 100 --eps 1e-6 --roberta_model ./drop_dataset/roberta.large --gcn_steps 3 --use_gcn\n",
      "Namespace(batch_size=3, bert_learning_rate=1.5e-05, bert_weight_decay=0.01, cuda=True, data_dir='./drop_dataset', dropout=0.1, eps=1e-06, eval_batch_size=5, gcn_steps=3, gpu_num=1, grad_clipping=1.0, gradient_accumulation_steps=4, learning_rate=0.0005, log_file='train.log', log_per_updates=100, max_epoch=3, optimizer='adam', pre_path=None, roberta_model='./drop_dataset/roberta.large', save_dir='./numnet_plus_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01', seed=345, tag_mspan=False, use_gcn=True, warmup=0.06, warmup_schedule='warmup_linear', weight_decay=5e-05)\n",
      "11/27/2020 11:28:05 Loading data...\n",
      "Load data from cached_roberta_train.pkl.\n",
      "Load data size 74321.\n",
      "Load data from cached_roberta_dev.pkl.\n",
      "Load data size 9536.\n",
      "11/27/2020 11:28:49 Num update steps 18580!\n",
      "11/27/2020 11:28:49 Build bert model.\n",
      "11/27/2020 11:29:01 Build Drop model.\n",
      "11/27/2020 11:29:01 Build optimizer etc...\n",
      "11/27/2020 11:29:09 At epoch 1\n",
      "11/27/2020 11:29:09 Updates[     0] train loss[12.65932] train em[0.00000] f1[0.00000] remaining[4:03:29]\n",
      "/home/sbisoyi/numnet_plus/tools/optimizer.py:132: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
      "11/27/2020 11:35:00 Updates[   100] train loss[7.20094] train em[0.03175] f1[0.04979] remaining[4:26:31]\n",
      "11/27/2020 11:41:21 Updates[   200] train loss[4.77183] train em[0.12667] f1[0.16422] remaining[4:31:15]\n",
      "11/27/2020 11:47:48 Updates[   300] train loss[3.75805] train em[0.19167] f1[0.23769] remaining[4:30:15]\n",
      "11/27/2020 11:54:10 Updates[   400] train loss[3.54694] train em[0.24667] f1[0.29413] remaining[4:25:37]\n",
      "11/27/2020 12:00:35 Updates[   500] train loss[3.24590] train em[0.28167] f1[0.33710] remaining[4:20:41]\n",
      "11/27/2020 12:07:01 Updates[   600] train loss[2.92171] train em[0.32750] f1[0.38398] remaining[4:15:22]\n",
      "11/27/2020 12:13:25 Updates[   700] train loss[2.91396] train em[0.35000] f1[0.40643] remaining[4:09:29]\n",
      "11/27/2020 12:19:47 Updates[   800] train loss[2.92538] train em[0.35750] f1[0.40603] remaining[4:03:21]\n",
      "11/27/2020 12:26:08 Updates[   900] train loss[2.73685] train em[0.37833] f1[0.43469] remaining[3:57:07]\n",
      "11/27/2020 12:32:31 Updates[  1000] train loss[2.61311] train em[0.38083] f1[0.43238] remaining[3:51:00]\n",
      "11/27/2020 12:38:59 Updates[  1100] train loss[2.62288] train em[0.38833] f1[0.43929] remaining[3:45:02]\n",
      "11/27/2020 12:45:26 Updates[  1200] train loss[2.49207] train em[0.37667] f1[0.43219] remaining[3:39:01]\n",
      "11/27/2020 12:51:49 Updates[  1300] train loss[2.49082] train em[0.40583] f1[0.46545] remaining[3:32:44]\n",
      "11/27/2020 12:58:12 Updates[  1400] train loss[2.43565] train em[0.42667] f1[0.47897] remaining[3:26:25]\n",
      "11/27/2020 01:04:40 Updates[  1500] train loss[2.25616] train em[0.45750] f1[0.50816] remaining[3:20:16]\n",
      "11/27/2020 01:11:04 Updates[  1600] train loss[2.35471] train em[0.43833] f1[0.48917] remaining[3:13:57]\n",
      "11/27/2020 01:17:29 Updates[  1700] train loss[2.16203] train em[0.46250] f1[0.51985] remaining[3:07:40]\n",
      "11/27/2020 01:23:52 Updates[  1800] train loss[2.36858] train em[0.47000] f1[0.51158] remaining[3:01:19]\n",
      "11/27/2020 01:30:14 Updates[  1900] train loss[2.37093] train em[0.48500] f1[0.53293] remaining[2:54:56]\n",
      "11/27/2020 01:36:39 Updates[  2000] train loss[2.25855] train em[0.47667] f1[0.52620] remaining[2:48:37]\n",
      "11/27/2020 01:43:05 Updates[  2100] train loss[2.19845] train em[0.49667] f1[0.55193] remaining[2:42:19]\n",
      "11/27/2020 01:49:28 Updates[  2200] train loss[2.11474] train em[0.49833] f1[0.55173] remaining[2:35:57]\n",
      "11/27/2020 01:55:49 Updates[  2300] train loss[2.07701] train em[0.49500] f1[0.54683] remaining[2:29:32]\n",
      "11/27/2020 02:02:14 Updates[  2400] train loss[2.11584] train em[0.49500] f1[0.55317] remaining[2:23:12]\n",
      "11/27/2020 02:08:36 Updates[  2500] train loss[2.07186] train em[0.50500] f1[0.57150] remaining[2:16:48]\n",
      "11/27/2020 02:15:02 Updates[  2600] train loss[2.00978] train em[0.49167] f1[0.54783] remaining[2:10:28]\n",
      "11/27/2020 02:21:26 Updates[  2700] train loss[2.11857] train em[0.51250] f1[0.56056] remaining[2:04:07]\n",
      "11/27/2020 02:27:49 Updates[  2800] train loss[2.07145] train em[0.49083] f1[0.53627] remaining[1:57:43]\n",
      "11/27/2020 02:34:08 Updates[  2900] train loss[2.11648] train em[0.48333] f1[0.54126] remaining[1:51:19]\n",
      "11/27/2020 02:40:30 Updates[  3000] train loss[1.87229] train em[0.52583] f1[0.57943] remaining[1:44:55]\n",
      "11/27/2020 02:46:51 Updates[  3100] train loss[1.89552] train em[0.50667] f1[0.56422] remaining[1:38:31]\n",
      "11/27/2020 02:53:12 Updates[  3200] train loss[2.04933] train em[0.50000] f1[0.55648] remaining[1:32:08]\n",
      "11/27/2020 02:59:36 Updates[  3300] train loss[1.93142] train em[0.53333] f1[0.58454] remaining[1:25:46]\n",
      "11/27/2020 03:05:58 Updates[  3400] train loss[1.84405] train em[0.51917] f1[0.57989] remaining[1:19:23]\n",
      "11/27/2020 03:12:21 Updates[  3500] train loss[1.80682] train em[0.56167] f1[0.60840] remaining[1:13:01]\n",
      "11/27/2020 03:18:41 Updates[  3600] train loss[2.06406] train em[0.55083] f1[0.59358] remaining[1:06:37]\n",
      "11/27/2020 03:25:04 Updates[  3700] train loss[1.85680] train em[0.52833] f1[0.58872] remaining[1:00:15]\n",
      "11/27/2020 03:31:24 Updates[  3800] train loss[1.76959] train em[0.54000] f1[0.59856] remaining[0:53:52]\n",
      "11/27/2020 03:37:51 Updates[  3900] train loss[1.93097] train em[0.54833] f1[0.60494] remaining[0:47:30]\n",
      "11/27/2020 03:44:14 Updates[  4000] train loss[1.96694] train em[0.54167] f1[0.59419] remaining[0:41:07]\n",
      "11/27/2020 03:50:35 Updates[  4100] train loss[1.87314] train em[0.51750] f1[0.56993] remaining[0:34:45]\n",
      "11/27/2020 03:56:56 Updates[  4200] train loss[1.77830] train em[0.55250] f1[0.60359] remaining[0:28:22]\n",
      "11/27/2020 04:03:19 Updates[  4300] train loss[1.80762] train em[0.55333] f1[0.61167] remaining[0:21:59]\n",
      "11/27/2020 04:09:41 Updates[  4400] train loss[1.81496] train em[0.56667] f1[0.61387] remaining[0:15:37]\n",
      "11/27/2020 04:16:02 Updates[  4500] train loss[1.79851] train em[0.56167] f1[0.61323] remaining[0:09:14]\n",
      "11/27/2020 04:22:33 Updates[  4600] train loss[1.64363] train em[0.57000] f1[0.61214] remaining[0:02:52]\n",
      "11/27/2020 04:29:08 Updates[  4700] train loss[1.78203] train em[0.56583] f1[0.62313] remaining[-1 day, 23:56:29]\n",
      "11/27/2020 04:35:42 Updates[  4800] train loss[1.80623] train em[0.54083] f1[0.60065] remaining[-1 day, 23:50:06]\n",
      "11/27/2020 04:42:14 Updates[  4900] train loss[1.68300] train em[0.57250] f1[0.62953] remaining[-1 day, 23:43:42]\n",
      "11/27/2020 04:48:49 Updates[  5000] train loss[1.81099] train em[0.55000] f1[0.61095] remaining[-1 day, 23:37:18]\n",
      "11/27/2020 04:55:24 Updates[  5100] train loss[1.75876] train em[0.55750] f1[0.61000] remaining[-1 day, 23:30:53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/27/2020 05:01:57 Updates[  5200] train loss[1.87204] train em[0.56500] f1[0.61992] remaining[-1 day, 23:24:28]\n",
      "11/27/2020 05:08:30 Updates[  5300] train loss[1.70402] train em[0.57000] f1[0.62010] remaining[-1 day, 23:18:03]\n",
      "11/27/2020 05:15:05 Updates[  5400] train loss[1.78042] train em[0.57417] f1[0.62145] remaining[-1 day, 23:11:38]\n",
      "11/27/2020 05:21:40 Updates[  5500] train loss[1.73892] train em[0.56833] f1[0.61990] remaining[-1 day, 23:05:11]\n",
      "11/27/2020 05:28:14 Updates[  5600] train loss[1.76964] train em[0.58667] f1[0.63622] remaining[-1 day, 22:58:45]\n",
      "11/27/2020 05:34:52 Updates[  5700] train loss[1.49069] train em[0.58500] f1[0.64064] remaining[-1 day, 22:52:18]\n",
      "11/27/2020 05:41:32 Updates[  5800] train loss[1.58159] train em[0.60417] f1[0.65244] remaining[-1 day, 22:45:50]\n",
      "11/27/2020 05:48:08 Updates[  5900] train loss[1.73505] train em[0.57750] f1[0.62606] remaining[-1 day, 22:39:23]\n",
      "11/27/2020 05:54:40 Updates[  6000] train loss[1.61504] train em[0.57583] f1[0.62522] remaining[-1 day, 22:32:56]\n",
      "11/27/2020 06:01:15 Updates[  6100] train loss[1.76531] train em[0.55667] f1[0.61783] remaining[-1 day, 22:26:28]\n",
      "11/27/2020 06:19:00 Eval 9536 examples, result in epoch 1, eval loss 377359.9682645736, eval em 0.6857172818791947 eval f1 0.7193414429530205.\n",
      "model saved to ./numnet_plus_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01/checkpoint_best\n",
      "11/27/2020 06:19:25 Best eval F1 0.7193414429530205 at epoch 1\n",
      "11/27/2020 06:19:25 At epoch 2\n",
      "11/27/2020 06:19:49 Updates[  6200] train loss[1.93698] train em[0.57692] f1[0.65500] remaining[203 days, 12:27:20]\n",
      "11/27/2020 06:26:14 Updates[  6300] train loss[1.50443] train em[0.62167] f1[0.68188] remaining[12 days, 8:14:30]\n",
      "11/27/2020 06:32:22 Updates[  6400] train loss[1.44069] train em[0.63000] f1[0.67517] remaining[6 days, 7:36:53]\n",
      "11/27/2020 06:38:18 Updates[  6500] train loss[1.49026] train em[0.61750] f1[0.66361] remaining[4 days, 5:14:39]\n",
      "11/27/2020 06:44:11 Updates[  6600] train loss[1.57523] train em[0.60833] f1[0.66045] remaining[3 days, 3:36:07]\n",
      "11/27/2020 06:50:05 Updates[  6700] train loss[1.31881] train em[0.61000] f1[0.65633] remaining[2 days, 12:02:50]\n",
      "11/27/2020 06:55:56 Updates[  6800] train loss[1.54562] train em[0.59667] f1[0.64947] remaining[2 days, 1:34:59]\n",
      "11/27/2020 07:01:48 Updates[  6900] train loss[1.44901] train em[0.59500] f1[0.64858] remaining[1 day, 18:03:26]\n",
      "11/27/2020 07:07:41 Updates[  7000] train loss[1.34860] train em[0.60500] f1[0.66218] remaining[1 day, 12:22:23]\n",
      "11/27/2020 07:13:34 Updates[  7100] train loss[1.43374] train em[0.63417] f1[0.68951] remaining[1 day, 7:55:18]\n",
      "11/27/2020 07:19:27 Updates[  7200] train loss[1.39424] train em[0.62250] f1[0.67391] remaining[1 day, 4:20:08]\n",
      "11/27/2020 07:25:21 Updates[  7300] train loss[1.47486] train em[0.62500] f1[0.67015] remaining[1 day, 1:22:53]\n",
      "11/27/2020 07:31:11 Updates[  7400] train loss[1.45923] train em[0.63750] f1[0.68834] remaining[22:53:48]\n",
      "11/27/2020 07:37:07 Updates[  7500] train loss[1.40460] train em[0.61333] f1[0.67060] remaining[20:46:55]\n",
      "11/27/2020 07:43:03 Updates[  7600] train loss[1.39061] train em[0.62000] f1[0.66452] remaining[18:57:12]\n",
      "11/27/2020 07:48:56 Updates[  7700] train loss[1.48112] train em[0.62917] f1[0.67918] remaining[17:21:13]\n",
      "11/27/2020 07:54:47 Updates[  7800] train loss[1.48834] train em[0.61083] f1[0.66178] remaining[15:56:22]\n",
      "11/27/2020 08:00:44 Updates[  7900] train loss[1.45055] train em[0.63500] f1[0.68847] remaining[14:40:55]\n",
      "11/27/2020 08:06:40 Updates[  8000] train loss[1.31951] train em[0.63000] f1[0.68344] remaining[13:33:09]\n",
      "11/27/2020 08:12:32 Updates[  8100] train loss[1.34334] train em[0.63167] f1[0.68532] remaining[12:31:47]\n",
      "11/27/2020 08:18:26 Updates[  8200] train loss[1.35402] train em[0.61833] f1[0.67222] remaining[11:36:00]\n",
      "11/27/2020 08:24:20 Updates[  8300] train loss[1.40381] train em[0.62583] f1[0.68125] remaining[10:44:57]\n",
      "11/27/2020 08:30:14 Updates[  8400] train loss[1.34185] train em[0.61833] f1[0.67931] remaining[9:57:59]\n",
      "11/27/2020 08:36:06 Updates[  8500] train loss[1.41110] train em[0.62250] f1[0.68353] remaining[9:14:33]\n",
      "11/27/2020 08:42:00 Updates[  8600] train loss[1.40655] train em[0.60583] f1[0.66238] remaining[8:34:15]\n",
      "11/27/2020 08:47:53 Updates[  8700] train loss[1.46187] train em[0.63083] f1[0.68572] remaining[7:56:42]\n",
      "11/27/2020 08:53:48 Updates[  8800] train loss[1.23505] train em[0.64500] f1[0.69332] remaining[7:21:36]\n",
      "11/27/2020 08:59:40 Updates[  8900] train loss[1.37696] train em[0.63083] f1[0.68180] remaining[6:48:38]\n",
      "11/27/2020 09:05:34 Updates[  9000] train loss[1.37524] train em[0.62000] f1[0.66627] remaining[6:17:36]\n",
      "11/27/2020 09:11:29 Updates[  9100] train loss[1.41634] train em[0.62917] f1[0.68900] remaining[5:48:19]\n",
      "11/27/2020 09:17:22 Updates[  9200] train loss[1.23932] train em[0.64583] f1[0.69308] remaining[5:20:34]\n",
      "11/27/2020 09:23:16 Updates[  9300] train loss[1.28435] train em[0.62667] f1[0.68136] remaining[4:54:14]\n",
      "11/27/2020 09:29:11 Updates[  9400] train loss[1.25395] train em[0.62750] f1[0.69027] remaining[4:29:11]\n",
      "11/27/2020 09:35:05 Updates[  9500] train loss[1.54976] train em[0.59917] f1[0.65645] remaining[4:05:17]\n",
      "11/27/2020 09:41:00 Updates[  9600] train loss[1.32663] train em[0.62833] f1[0.67477] remaining[3:42:27]\n",
      "11/27/2020 09:46:56 Updates[  9700] train loss[1.41522] train em[0.61333] f1[0.67055] remaining[3:20:35]\n",
      "11/27/2020 09:52:50 Updates[  9800] train loss[1.36558] train em[0.63083] f1[0.68028] remaining[2:59:35]\n",
      "11/27/2020 09:58:47 Updates[  9900] train loss[1.45980] train em[0.60917] f1[0.66697] remaining[2:39:25]\n",
      "11/27/2020 10:04:41 Updates[ 10000] train loss[1.33243] train em[0.63417] f1[0.68737] remaining[2:19:59]\n",
      "11/27/2020 10:10:37 Updates[ 10100] train loss[1.38224] train em[0.63583] f1[0.68932] remaining[2:01:15]\n",
      "11/27/2020 10:16:32 Updates[ 10200] train loss[1.35435] train em[0.60917] f1[0.66320] remaining[1:43:10]\n",
      "11/27/2020 10:22:24 Updates[ 10300] train loss[1.44957] train em[0.62667] f1[0.68234] remaining[1:25:39]\n",
      "11/27/2020 10:28:19 Updates[ 10400] train loss[1.28220] train em[0.62417] f1[0.68141] remaining[1:08:42]\n",
      "11/27/2020 10:34:14 Updates[ 10500] train loss[1.38206] train em[0.63167] f1[0.68186] remaining[0:52:16]\n",
      "11/27/2020 10:40:09 Updates[ 10600] train loss[1.33739] train em[0.62250] f1[0.67878] remaining[0:36:19]\n",
      "11/27/2020 10:46:04 Updates[ 10700] train loss[1.34009] train em[0.63250] f1[0.68440] remaining[0:20:48]\n",
      "11/27/2020 10:52:00 Updates[ 10800] train loss[1.33055] train em[0.62583] f1[0.67495] remaining[0:05:42]\n",
      "11/27/2020 10:57:55 Updates[ 10900] train loss[1.41126] train em[0.62833] f1[0.68251] remaining[-1 day, 23:50:59]\n",
      "11/27/2020 11:03:52 Updates[ 11000] train loss[1.15465] train em[0.64500] f1[0.69203] remaining[-1 day, 23:36:39]\n",
      "11/27/2020 11:09:48 Updates[ 11100] train loss[1.33033] train em[0.63667] f1[0.69548] remaining[-1 day, 23:22:39]\n",
      "11/27/2020 11:15:44 Updates[ 11200] train loss[1.25344] train em[0.63250] f1[0.68252] remaining[-1 day, 23:08:58]\n",
      "11/27/2020 11:21:42 Updates[ 11300] train loss[1.36652] train em[0.63000] f1[0.68480] remaining[-1 day, 22:55:36]\n",
      "11/27/2020 11:27:37 Updates[ 11400] train loss[1.24933] train em[0.63917] f1[0.70327] remaining[-1 day, 22:42:30]\n",
      "11/27/2020 11:33:32 Updates[ 11500] train loss[1.29064] train em[0.64917] f1[0.70441] remaining[-1 day, 22:29:41]\n",
      "11/27/2020 11:39:27 Updates[ 11600] train loss[1.39295] train em[0.63500] f1[0.67754] remaining[-1 day, 22:17:08]\n",
      "11/27/2020 11:45:20 Updates[ 11700] train loss[1.22550] train em[0.63750] f1[0.69725] remaining[-1 day, 22:04:49]\n",
      "11/27/2020 11:51:16 Updates[ 11800] train loss[1.17896] train em[0.64000] f1[0.69379] remaining[-1 day, 21:52:43]\n",
      "11/27/2020 11:57:10 Updates[ 11900] train loss[1.15674] train em[0.65667] f1[0.71635] remaining[-1 day, 21:40:51]\n",
      "11/28/2020 12:03:04 Updates[ 12000] train loss[1.23317] train em[0.66917] f1[0.71898] remaining[-1 day, 21:29:11]\n",
      "11/28/2020 12:08:58 Updates[ 12100] train loss[1.25783] train em[0.62667] f1[0.68837] remaining[-1 day, 21:17:43]\n",
      "11/28/2020 12:14:55 Updates[ 12200] train loss[1.36060] train em[0.63167] f1[0.68417] remaining[-1 day, 21:06:25]\n",
      "11/28/2020 12:20:48 Updates[ 12300] train loss[1.21147] train em[0.65083] f1[0.70110] remaining[-1 day, 20:55:19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/28/2020 12:36:24 Eval 9536 examples, result in epoch 2, eval loss 377359.89725759614, eval em 0.7230494966442953 eval f1 0.759037332214766.\n",
      "model saved to ./numnet_plus_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01/checkpoint_best\n",
      "11/28/2020 12:36:49 Best eval F1 0.759037332214766 at epoch 2\n",
      "11/28/2020 12:36:49 At epoch 3\n",
      "11/28/2020 12:37:35 Updates[ 12400] train loss[0.98438] train em[0.59615] f1[0.67192] remaining[195 days, 2:08:44]\n",
      "11/28/2020 12:43:31 Updates[ 12500] train loss[1.11218] train em[0.66583] f1[0.71876] remaining[22 days, 2:59:06]\n",
      "11/28/2020 12:49:23 Updates[ 12600] train loss[0.99951] train em[0.68167] f1[0.72899] remaining[11 days, 13:31:00]\n",
      "11/28/2020 12:55:17 Updates[ 12700] train loss[0.90020] train em[0.69583] f1[0.75105] remaining[7 days, 17:57:16]\n",
      "11/28/2020 01:01:17 Updates[ 12800] train loss[1.08810] train em[0.68917] f1[0.74450] remaining[5 days, 18:41:55]\n",
      "11/28/2020 01:07:12 Updates[ 12900] train loss[1.06993] train em[0.67917] f1[0.73387] remaining[4 days, 13:49:09]\n",
      "11/28/2020 01:13:07 Updates[ 13000] train loss[1.07695] train em[0.66917] f1[0.72197] remaining[3 days, 18:19:38]\n",
      "11/28/2020 01:19:01 Updates[ 13100] train loss[1.10221] train em[0.66083] f1[0.71740] remaining[3 days, 4:16:33]\n",
      "11/28/2020 01:24:57 Updates[ 13200] train loss[0.99601] train em[0.68333] f1[0.74127] remaining[2 days, 17:39:29]\n",
      "11/28/2020 01:30:52 Updates[ 13300] train loss[0.93167] train em[0.69000] f1[0.75017] remaining[2 days, 9:20:38]\n",
      "11/28/2020 01:36:45 Updates[ 13400] train loss[1.12092] train em[0.67000] f1[0.72206] remaining[2 days, 2:38:59]\n",
      "11/28/2020 01:42:39 Updates[ 13500] train loss[1.02613] train em[0.68500] f1[0.72665] remaining[1 day, 21:08:32]\n",
      "11/28/2020 01:48:35 Updates[ 13600] train loss[1.11308] train em[0.67167] f1[0.73264] remaining[1 day, 16:31:37]\n",
      "11/28/2020 01:54:31 Updates[ 13700] train loss[1.15694] train em[0.66500] f1[0.72287] remaining[1 day, 12:36:02]\n",
      "11/28/2020 02:00:24 Updates[ 13800] train loss[0.95776] train em[0.67333] f1[0.72690] remaining[1 day, 9:12:50]\n",
      "11/28/2020 02:06:20 Updates[ 13900] train loss[0.94571] train em[0.70000] f1[0.74858] remaining[1 day, 6:15:50]\n",
      "11/28/2020 02:12:15 Updates[ 14000] train loss[0.99190] train em[0.67917] f1[0.73228] remaining[1 day, 3:39:59]\n",
      "11/28/2020 02:18:08 Updates[ 14100] train loss[1.02923] train em[0.67167] f1[0.72162] remaining[1 day, 1:21:35]\n",
      "11/28/2020 02:24:03 Updates[ 14200] train loss[1.05372] train em[0.68167] f1[0.72886] remaining[23:17:53]\n",
      "11/28/2020 02:29:59 Updates[ 14300] train loss[1.20711] train em[0.65667] f1[0.71560] remaining[21:26:30]\n",
      "11/28/2020 02:35:55 Updates[ 14400] train loss[1.01425] train em[0.68583] f1[0.73576] remaining[19:45:36]\n",
      "11/28/2020 02:41:50 Updates[ 14500] train loss[1.00299] train em[0.68417] f1[0.73310] remaining[18:13:40]\n",
      "11/28/2020 02:47:48 Updates[ 14600] train loss[0.96714] train em[0.69417] f1[0.74872] remaining[16:49:33]\n",
      "11/28/2020 02:53:40 Updates[ 14700] train loss[0.82358] train em[0.69500] f1[0.74382] remaining[15:32:07]\n",
      "11/28/2020 02:59:34 Updates[ 14800] train loss[1.04120] train em[0.68000] f1[0.74145] remaining[14:20:37]\n",
      "11/28/2020 03:05:29 Updates[ 14900] train loss[0.94347] train em[0.70333] f1[0.74614] remaining[13:14:22]\n",
      "11/28/2020 03:11:25 Updates[ 15000] train loss[1.11281] train em[0.67500] f1[0.72398] remaining[12:12:45]\n",
      "11/28/2020 03:17:19 Updates[ 15100] train loss[1.01796] train em[0.68000] f1[0.73879] remaining[11:15:13]\n",
      "11/28/2020 03:23:14 Updates[ 15200] train loss[0.98309] train em[0.69333] f1[0.74329] remaining[10:21:21]\n",
      "11/28/2020 03:29:09 Updates[ 15300] train loss[1.05237] train em[0.67833] f1[0.73143] remaining[9:30:47]\n",
      "11/28/2020 03:35:06 Updates[ 15400] train loss[0.91251] train em[0.69917] f1[0.74349] remaining[8:43:12]\n",
      "11/28/2020 03:41:01 Updates[ 15500] train loss[1.06225] train em[0.66667] f1[0.72855] remaining[7:58:17]\n",
      "11/28/2020 03:46:53 Updates[ 15600] train loss[0.99964] train em[0.67583] f1[0.73597] remaining[7:15:45]\n",
      "11/28/2020 03:52:45 Updates[ 15700] train loss[1.01479] train em[0.67583] f1[0.73452] remaining[6:35:27]\n",
      "11/28/2020 03:58:45 Updates[ 15800] train loss[1.06219] train em[0.66250] f1[0.72141] remaining[5:57:13]\n",
      "11/28/2020 04:04:39 Updates[ 15900] train loss[1.03335] train em[0.67917] f1[0.72942] remaining[5:20:47]\n",
      "11/28/2020 04:10:33 Updates[ 16000] train loss[0.92801] train em[0.68000] f1[0.73598] remaining[4:46:02]\n",
      "11/28/2020 04:16:27 Updates[ 16100] train loss[0.95520] train em[0.68250] f1[0.73404] remaining[4:12:50]\n",
      "11/28/2020 04:22:22 Updates[ 16200] train loss[1.04224] train em[0.68083] f1[0.73359] remaining[3:41:05]\n",
      "11/28/2020 04:28:15 Updates[ 16300] train loss[0.85031] train em[0.70583] f1[0.75461] remaining[3:10:38]\n",
      "11/28/2020 04:34:11 Updates[ 16400] train loss[1.11737] train em[0.66667] f1[0.71581] remaining[2:41:25]\n",
      "11/28/2020 04:40:06 Updates[ 16500] train loss[0.98824] train em[0.69500] f1[0.74375] remaining[2:13:21]\n",
      "11/28/2020 04:46:03 Updates[ 16600] train loss[0.88850] train em[0.70833] f1[0.75927] remaining[1:46:19]\n",
      "11/28/2020 04:51:58 Updates[ 16700] train loss[0.93351] train em[0.69083] f1[0.74455] remaining[1:20:16]\n",
      "11/28/2020 04:57:51 Updates[ 16800] train loss[0.89145] train em[0.70417] f1[0.75842] remaining[0:55:07]\n",
      "11/28/2020 05:03:45 Updates[ 16900] train loss[0.92078] train em[0.70750] f1[0.75302] remaining[0:30:50]\n",
      "11/28/2020 05:09:40 Updates[ 17000] train loss[1.08746] train em[0.67667] f1[0.72732] remaining[0:07:21]\n",
      "11/28/2020 05:15:33 Updates[ 17100] train loss[1.02129] train em[0.69417] f1[0.73810] remaining[-1 day, 23:44:36]\n",
      "11/28/2020 05:21:29 Updates[ 17200] train loss[0.93984] train em[0.69250] f1[0.74639] remaining[-1 day, 23:22:34]\n",
      "11/28/2020 05:27:24 Updates[ 17300] train loss[0.88276] train em[0.69667] f1[0.74621] remaining[-1 day, 23:01:10]\n",
      "11/28/2020 05:33:19 Updates[ 17400] train loss[0.90861] train em[0.69583] f1[0.74137] remaining[-1 day, 22:40:24]\n",
      "11/28/2020 05:39:16 Updates[ 17500] train loss[0.94991] train em[0.68417] f1[0.74016] remaining[-1 day, 22:20:13]\n",
      "11/28/2020 05:45:10 Updates[ 17600] train loss[0.90171] train em[0.68833] f1[0.74313] remaining[-1 day, 22:00:34]\n",
      "11/28/2020 05:51:04 Updates[ 17700] train loss[0.91621] train em[0.69833] f1[0.75156] remaining[-1 day, 21:41:27]\n",
      "11/28/2020 05:56:59 Updates[ 17800] train loss[0.94895] train em[0.70333] f1[0.76073] remaining[-1 day, 21:22:49]\n",
      "11/28/2020 06:02:54 Updates[ 17900] train loss[1.02957] train em[0.68250] f1[0.73744] remaining[-1 day, 21:04:38]\n",
      "11/28/2020 06:08:47 Updates[ 18000] train loss[0.93209] train em[0.70417] f1[0.75623] remaining[-1 day, 20:46:54]\n",
      "11/28/2020 06:14:42 Updates[ 18100] train loss[0.94620] train em[0.69000] f1[0.74958] remaining[-1 day, 20:29:35]\n",
      "11/28/2020 06:20:34 Updates[ 18200] train loss[0.92474] train em[0.69333] f1[0.75061] remaining[-1 day, 20:12:39]\n",
      "11/28/2020 06:26:28 Updates[ 18300] train loss[0.85448] train em[0.70083] f1[0.75569] remaining[-1 day, 19:56:06]\n",
      "11/28/2020 06:32:23 Updates[ 18400] train loss[0.97153] train em[0.68417] f1[0.72662] remaining[-1 day, 19:39:54]\n",
      "11/28/2020 06:38:15 Updates[ 18500] train loss[0.91880] train em[0.70083] f1[0.75830] remaining[-1 day, 19:24:02]\n",
      "11/28/2020 06:53:25 Eval 9536 examples, result in epoch 3, eval loss 377359.8569864372, eval em 0.7419253355704698 eval f1 0.7782434983221481.\n",
      "model saved to ./numnet_plus_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01/checkpoint_best\n",
      "11/28/2020 06:53:50 Best eval F1 0.7782434983221481 at epoch 3\n",
      "11/28/2020 06:53:50 done training in 69881 seconds!\n",
      "+ echo 'Starting evaluation...'\n",
      "Starting evaluation...\n",
      "+ TEST_CONFIG='--eval_batch_size 5 --pre_path ./numnet_plus_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01/checkpoint_best.pt --data_mode dev --dump_path ./numnet_plus_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01/dev.json              --inf_path ./drop_dataset/drop_dataset_dev.json'\n",
      "+ python ./roberta_predict.py --data_dir ./drop_dataset --save_dir ./numnet_plus_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01 --eval_batch_size 5 --pre_path ./numnet_plus_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01/checkpoint_best.pt --data_mode dev --dump_path ./numnet_plus_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01/dev.json --inf_path ./drop_dataset/drop_dataset_dev.json --roberta_model ./drop_dataset/roberta.large --gcn_steps 3 --use_gcn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Bert inference task. [-h] [--bert_learning_rate BERT_LEARNING_RATE]\r\n",
      "                            [--bert_weight_decay BERT_WEIGHT_DECAY]\r\n",
      "                            [--roberta_model ROBERTA_MODEL] [--use_gcn]\r\n",
      "                            [--gcn_steps GCN_STEPS] [--tag_mspan]\r\n",
      "                            [--pre_path PRE_PATH] [--data_mode DATA_MODE]\r\n",
      "                            [--inf_path INF_PATH] [--dump_path DUMP_PATH]\r\n",
      "                            [--eval_batch_size EVAL_BATCH_SIZE]\r\n",
      "Bert inference task.: error: unrecognized arguments: --data_dir ./drop_dataset --save_dir ./numnet_plus_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01\r\n"
     ]
    }
   ],
   "source": [
    "!sh train.sh 345 5e-4 1.5e-5 5e-5 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ DATA_PATH=drop_dataset/stage3_test_processed_data.json\n",
      "+ DUMP_PATH=prediction_stage3_test.json\n",
      "+ TMSPAN=\n",
      "+ PRE_PATH=./numnet_plus_numeric_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01/checkpoint_best.pt\n",
      "+ BERT_CONFIG='--roberta_model drop_dataset/roberta.large'\n",
      "+ '[' == tag_mspan ']'\n",
      "eval.sh: line 12: [: ==: unary operator expected\n",
      "+ echo 'Use mspan model...'\n",
      "Use mspan model...\n",
      "+ MODEL_CONFIG='--gcn_steps 3 --use_gcn'\n",
      "+ echo 'Starting evaluation...'\n",
      "Starting evaluation...\n",
      "+ TEST_CONFIG='--eval_batch_size 1 --pre_path ./numnet_plus_numeric_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01/checkpoint_best.pt --data_mode dev --dump_path prediction_stage3_test.json              --inf_path drop_dataset/stage3_test_processed_data.json'\n",
      "+ python roberta_predict.py --eval_batch_size 1 --pre_path ./numnet_plus_numeric_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01/checkpoint_best.pt --data_mode dev --dump_path prediction_stage3_test.json --inf_path drop_dataset/stage3_test_processed_data.json --roberta_model drop_dataset/roberta.large --gcn_steps 3 --use_gcn\n",
      "Build bert model.\n",
      "Build Drop model.\n",
      "Load from pre path ./numnet_plus_numeric_345_LR_5e-4_BLR_1.5e-5_WD_5e-5_BWD_0.01/checkpoint_best.pt.\n",
      "Load data from drop_dataset/stage3_test_processed_data.json.\n",
      "Reading file at %s drop_dataset/stage3_test_processed_data.json\n",
      "Reading the dataset\n",
      "100%|██████████████████████████████████████████| 39/39 [00:00<00:00, 627.82it/s]\n",
      "Skipped 0 questions, kept 39 questions.\n",
      "Load data size 39.\n",
      "Start inference...\n",
      "100%|███████████████████████████████████████████| 39/39 [00:01<00:00, 19.60it/s]\n"
     ]
    }
   ],
   "source": [
    "!sh eval.sh drop_dataset/stage3_test_processed_data.json prediction_stage3_test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact-match accuracy 0.00\r\n",
      "F1 score 0.00\r\n",
      "0.00   &   0.00\r\n",
      "----\r\n",
      "number: 39 (100.00%)\r\n",
      "  Exact-match accuracy 0.000\r\n",
      "  F1 score 0.000\r\n"
     ]
    }
   ],
   "source": [
    "!python drop_eval.py --gold_path drop_dataset/stage3_test_with_answer_processed_data.json --prediction_path prediction_stage3_test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3-basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
